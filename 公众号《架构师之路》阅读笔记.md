## 公众号《架构师之路》阅读笔记

### 《究竟啥才是互联网架构“高可用”》

- https://mp.weixin.qq.com/s/p0LsxT-JUS7zYg23M7nupQ

- 高可用主要指 “`时间`”
- `单点`是高可用的大敌
- 保证高可用的核心是：`冗余（集群）`
- 避免人工恢复故障：`自动故障转移`
- 架构的每一层都要做 冗余 + 自动故障转移
  - 反向代理层：以nginx为例：有两台nginx，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是`keepalived`存活探测，相同`virtual IP`提供服务。当nginx挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到`shadow-nginx`，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的。
  - 站点层：假设反向代理层是`nginx`，`nginx.conf`里能够配置多个web后端，并且nginx能够探测到多个后端的存活性。当web-server挂了的时候，nginx能够探测到，会自动的进行故障转移，将流量自动迁移到其他的web-server，整个过程由`nginx自动完成`，对调用方是透明的。
  - 服务层：`“服务连接池”`会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。当service挂了的时候，service-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的service，整个过程由连接池自动完成，对调用方是透明的（所以说RPC-client中的服务连接池是很重要的基础组件）。
  - 缓存层：
    - 利用客户端的封装，service对cache进行双读或者双写。缓存层也可以通过支持主从同步的缓存集群来解决缓存层的高可用问题。以redis为例，redis天然支持主从同步，redis官方也有sentinel哨兵机制，来做redis的存活性检测。当redis主挂了的时候，sentinel能够探测到，会通知调用方访问新的redis，整个过程由`sentinel和redis集群`配合完成，对调用方是透明的。
    - 将kv缓存封装成服务集群，上游设置一个代理（代理可以用集群冗余的方式保证高可用），代理的后端根据缓存访问的key水平切分成若干个实例，每个实例的访问并不做高可用。缓存实例挂了屏蔽：当有水平切分的实例挂掉时，代理层直接返回cache miss，此时缓存挂掉对调用方也是透明的。key水平切分实例减少，不建议做re-hash，这样容易引发缓存数据的不一致。
  - 数据库层：大部分互联网技术，数据库层都用了“`主从同步，读写分离`”架构，所以数据库层的高可用，又分为“读库高可用”与“写库高可用”两类。`写master，读slave`
    - 读的高可用：既然冗余了读库，一般来说就至少有2个从库，“`数据库连接池`”会建立与读库多个连接，每次请求会路由到这些读库。当读库挂了的时候，db-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的读库，整个过程由连接池自动完成，对调用方是透明的（所以说DAO中的数据库连接池是很重要的基础组件）。
    - 写的高可用：以mysql为例，可以设置两个`mysql双主同步`，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是`keepalived存活探测`，相同virtual IP提供服务。自动故障转移：当写库挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-db-master，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的

### 《怎么理解分布式、高并发、多线程？》

- https://mp.weixin.qq.com/s/k1Fz0NCN8KyV3VHF0nSGuA
- 分布式
  - 水平扩展：当一台机器扛不住流量时，就通过添加机器的方式，将流量平分到所有服务器上，所有机器都可以提供相当的服务
  - 垂直扩展：前端有多种查询需求时，一台机器扛不住，可以将不同的需求分发到不同的机器上，比如A机器处理余票查询的请求，B机器处理支付的请求。
- 高并发：
  - 高并发可以通过`分布式`技术去解决，将并发流量分到不同的物理服务器上。但除此之外，还可以有很多其他优化手段：比如使用`缓存系统`，将所有的，`静态内容放到CDN等`；还可以使用`多线程`技术将一台服务器的服务能力最大化。
    - 服务并发低时候写数据库，并发高时候通过消息队列写缓存。缓存定期持久化到数据库
    - 服务读数据直接从缓存读

### 《一次彻底搞透协议设计》

- https://mp.weixin.qq.com/s/wr7chJqpOBbv3M3JXD1wXg
- 分层：
  - 应用层
    - 文本（HTTP）
      - 可读性好，可扩展性好，解析效率不高，对二进制不友好
    - 二进制（IP）
      - 定长包头，可扩展变长包体，每个字段有固定的含义
      - 可读性差，难以调试。扩展性不好。解析效率高。支持二进制流
      - Protobuf 是常见的变长包体协议
    - 流式XML（XMPP）
      - 可读性好，扩展性好
      - 解析代价超高，DOM树
      - 有效数据传输效率低
      - 对二进制不友好
  - 安全层
    - SSL
    - 自己实现
      - 一人一密（uid，手机号，qq号等）
      - 一次一密
  - 传输层
    - TCP
    - epoll 可以抗单机几十万连接

### 《互联网架构，究竟为啥要做服务化》

- https://mp.weixin.qq.com/s/S6ga8y88qaAjbKjuKMrowQ
- 没有服务层的痛点：
  - 代码到处拷贝：在有用户服务之前，各个业务线都是自己通过DAO写SQL访问user库来存取用户数据，这无形中就导致了代码的拷贝。
  - 复杂性扩散：如果没有统一的服务层，各个业务线都需要关注`缓存的引入`导致的复杂性。如果没有统一的服务层，各个业务线都需要关注`分库分表的引入`导致的复杂性。
  - 库的复用与耦合：库的版本维护会导致业务线之间的耦合。
  - SQL质量无法保障，业务互相影响：假如业务线A写了一个全表扫描的SQL，导致数据库的CPU100%，影响的不只是一个业务线，而是所有的业务线都会受影响。
  - DB耦合：典型的，通过join数据表来实现各自业务线的一些业务逻辑。
- 引入服务层的好处：
  - 调用方便
  - 复用性高，避免代码拷贝：所有user数据的存取，都通过user-service来进行，代码只此一份，不存在拷贝。升级一处升级，bug修改一处修改。
  - 屏蔽底层复杂度：在没有服务层之前，所有业务线都需要关注缓存、分库分表这些细节。
  - SQL质量得到保障
  - 数据库解耦
  - 服务层提供有限接口，无限性能：服务化之后，服务只提供有限的通用接口，理论上服务集群能够提供无限性能，性能出现瓶颈，服务层一处集中优化。

### 《拜托，面试别再问我TopK了》

- https://mp.weixin.qq.com/s/FFsvWXiaZK96PtUg-mmtEw
- 排序：O(n*lg(n))
- 局部排序（冒泡）：O(n*k)
- 堆：O(n*lg(k))
  - 每一次堆调整是lg(k)
- 随机选择：
  - 分治法：子问题都要解决（快排）
  - 减治法：子问题只解决一个（二分查找）
  - 转化为使用`快排的partition求第k大的数O(n)`

- 复习时间：
  - 2019年03月25日





### 《数据库索引，到底是什么做的》

- https://mp.weixin.qq.com/s/YMbRJwyjutGMD1KpI_fS0A
- 数据库建立索引是为了提高`查找`速度
- 索引为什么不设计成哈希，而是设计成为树形
  - 索引设计成树形，和SQL的需求相关。
  - 但是对于**排序查询**的SQL需求：**哈希**型的索引，时间复杂度会退化为O(n)，而**树型**的“有序”特性，依然能够保持O(log(n)) 的高效率。
  - InnoDB并`不支持`哈希索引。
- 二叉树为什么不用来做索引
  - 当数据量大的时候，树的`高度会比较高`，数据量大的时候，查询会比较慢；
  - 每个节点只存储一个记录，可能导致一次查询有很多次磁盘IO；
- B树：
  - 不再是二叉搜索，而是m叉搜索；高度能够大大降低；
  - 叶子节点，非叶子节点，都存储数据；
  - B树被作为实现索引的数据结构被创造出来，是因为它能够完美的利用“局部性原理”。每个节点可以存储j个记录，如果将节点大小设置为页大小，例如4K，能够充分的利用预读的特性，极大减少磁盘IO；
  - 获取所有的节点需要`中序遍历`
- B+树
  - 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上；
  - 叶子之间，增加了链表，获取所有节点，`不再需要中序遍历`；
  - 范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯；
  - 叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储；
  - 非叶子节点，不存储实际记录，而只存储记录的KEY的话，`那么在相同内存的情况下，B+树能够存储更多索引`；

- 复习时间：
  - 2019年03月25日



### 《1分钟了解MyISAM与InnoDB的索引差异》

- https://mp.weixin.qq.com/s/FUXPXKfKyjxAvMUFHZm9UQ
- MyISAM的索引
  - MyISAM的`索引`与`行记录`是分开存储的，叫做**非聚集索引**（UnClustered Index）
  - 有连续聚集的区域单独存储行记录
  - 主键索引的叶子节点，存储主键，与对应行记录的指针
  - 普通索引的叶子结点，存储索引列，与对应行记录的指针
- InnoDB的索引
  - InnoDB的**主键索引与**行记录是存储在一起的，故叫做**聚集索引**（Clustered Index）：
  - 没有单独区域存储行记录
  - 键索引的叶子节点，存储主键，与对应行记录（而不是指针）
  - 普通索引的叶子节点，存储`主键`（也不是指针）
  - 不建议使用较长的列做主键，例如char(64)，因为`所有的普通索引都会存储主键`，会导致普通索引过于庞大；
  - `建议使用趋势递增的key做主键`，由于数据行与索引一体，这样不至于插入记录时，有大量索引分裂，行记录移动；
  - 查询普通索引其实扫了`两遍`索引树，先查普通索引找到主键，然后通过主键索引找到行记录
- 复习：
  - 2019年03月28日

### 《InnoDB并发如此高，原因竟然在这》

- 技术上如何进行并发控制
  - 锁
  - 数据多版本
- 数据多版本（写时也能读）
  - 写任务发生时，将数据克隆一份，以版本号区分；
  - 写任务操作新克隆的数据，直至提交；
  - 并发读任务可以继续读取旧版本的数据，不至于阻塞
- redo
  - 磁盘**随机写**性能较低，如果每次都刷盘，会极大影响数据库的吞吐量。
  - 将修改行为先写到redo日志里（此时变成了**顺序写**），再定期将数据刷到磁盘上，这样能极大提高性能。
- MVVC 读取的旧版本数据在哪
  - 旧版本数据存储在回滚段里；
- InnoDB为何能够做到这么高的并发
  - 回滚段里的数据，其实是历史数据的快照（snapshot），这些数据是不会被修改，select可以肆无忌惮的并发读取他们。
  - **快照读**（Snapshot Read），这种**一致性不加锁的读**（Consistent Nonlocking Read），就是InnoDB并发如此之高的核心原因之一。
- 什么样的select是快照读？
  - 除非显示加锁，普通的select语句都是快照读
  - 这里的显示加锁，非快照读是指：
    - select … lock in share mode
    - select … for update

### 《InnoDB，5项最佳实践，知其所以然》

- https://mp.weixin.qq.com/s/JEJcgD36dpKgbUi7xo6DzA
- 关于count(*)
  - MyISAM会直接存储总行数，InnoDB则不会，需要按行扫描
  - 数据量大的表，InnoDB不要轻易select count(*)，性能消耗极大
  - 只有查询全表的总行数，MyISAM才会直接返回结果，当加了where条件后，两种存储引擎的处理方式类似
- 关于全文索引
  - MyISAM支持全文索引，InnoDB5.6之前不支持全文索引
  - 不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用数据库自带的全文索引，会导致小量请求占用大量数据库资源
  - 大数据量+高并发量的业务场景，全文索引，MyISAM也不是最优之选
- 关于事务
  - MyISAM不支持事务，InnoDB支持事务
  - 事务是选择InnoDB非常诱人的原因之一，它提供了commit，rollback，崩溃修复等能力。在系统异常崩溃时，MyISAM有一定几率造成文件损坏，这是非常烦的。但是，事务也非常耗性能，会影响吞吐量，建议只对一致性要求较高的业务使用复杂事务
  - MyISAM可以通过lock table表锁，来实现类似于事务的东西，但对数据库性能影响较大，强烈不推荐使用
- 关于外键
  - MyISAM不支持外键，InnoDB支持外键
  - 不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用外键，而建议由应用程序保证完整性
- 关于行锁与表锁
  - MyISAM只支持表锁，InnoDB可以支持行锁
  - 只要数据量和并发量较大，一律使用InnoDB
  - InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁
- InnoDB两个最牛逼的特点
  - 行锁
  - 事务

### 《InnoDB行锁，如何锁住一条不存在的记录》

- https://mp.weixin.qq.com/s/JLdprFfpZoK_v4zkw-EVbg
- MySQL默认的事务隔离级别是 `Repeated Read` (RR)
  - 读取到数据，都是其他事务已提交的数据
  - 同一个事务中，`相同的连续读，得到的结果应该是相同的`
  - 不会出现insert幻象读

- 复习
  - 2019年03月26日

### 《InnoDB，快照读，在RR和RC下有何差异》

- https://mp.weixin.qq.com/s/gjt9WdyTQRzx-hr_qIz_mw
- 读已提交：
  - 它解决“读脏”问题，保证读取到的数据行都是已提交事务写入的
  - 它可能存在“读幻影行”问题，同一个事务里，连续相同的read可能读到不同的结果集
- 可重复读
  - 它不但解决“读脏”问题，还解决了“读幻影行”问题，同一个事务里，连续相同的read读到相同的结果集
- 结论：
  - RC下，快照读总是能读到最新的行数据快照，当然，必须是已提交事务写入的
  - RR下，某个事务首次read记录的时间为T，未来不会读取到T时间之后已提交事务写入的记录，以保证连续相同的read读到相同的结果集（和事务开始时间无关，和首次读时间有关）
- 总结：
  - RR下，事务在第一个Read操作时，会建立Read View
  - RC下，事务在每次Read操作时，都会建立Read View

### 《插入InnoDB自增列，居然是表锁》

- https://mp.weixin.qq.com/s/kOMSD_Satu9v9ciZVvNw8Q
- 自增锁是一种特殊的`表级别锁`（table-level lock）
- 如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。
- 复习：
  - 2019年03月26日

### 《InnoDB并发插入，居然使用意向锁》

- https://mp.weixin.qq.com/s/iViStnwUyypwTkQHWDIR_w
- 意向锁的特点：
  - 意向锁，是一个表级别的锁(table-level locking)
  - **意向共享锁**(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁
    - select ... lock in share mode，要设置**IS锁**
  - **意向排它锁**(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁
    - select ... for update，要设置**IX锁**
- 意向锁协议：
  - 事务要获得某些行的S锁，必须先获得表的IS锁
  - 意向锁是兼容的，不是互斥的
- 插入意向锁：
  - 多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。
- InnoDB使用**插入意向锁**，可以提高插入并发；

### 《消息顺序性为何这么难》

- https://mp.weixin.qq.com/s/wF-jqn9QZAC8qsof3aAPoQ
- 邮件展示顺序，其实是以客户端发送时间为准的
- 秒杀活动时间判断，肯定得以服务器的时间为准，不可能让客户端修改本地时间，就能够提前秒杀
- 对于严格时序的业务场景，可以利用单点写db的seq/auto_inc_id生成单调递增的id，来保证顺序性。
  - 单点容易成为瓶颈
- 如果能接受误差不大
  - 可以始终分布式id生成算法来生成id，作为时序依据。
- 单点序列化
  - 数据库主从同步
  - GFS中文件的一致性
    - GFS(Google File System)为了保证文件的可用性，一份文件要存储多份，在多个上游对同一个文件进行写操作时，也是由一个主chunk-server先序列化写操作，再将序列化后的操作发送给其他chunk-server，来保证冗余文件的数据一致性的。
  - 单发消息：
    - 客户端序列化
  - 群发消息，服务器收到消息之后做服务器端单点序列化
    - 缺点：生成全局递增序列号的服务很容易成为系统瓶颈。
    - 改进：service做单点序列生成。保证一个群的消息落在同一个service上，这个service就可以用本地seq来序列化同一个群的所有消息，保证所有群友看到消息的时序是相同的。【id串行化】

### 《“ID串行化”是如何保证消息顺序性的》

- https://mp.weixin.qq.com/s/LgaiSqJGqX5a9JB1WSZ2_w
- 让同一个群gid的所有消息落在同一台服务器上处理

```
对连接池进行少量改动，获取连接时：
CPool.GetConnection()

画外音：返回任何一个可用服务连接。

升级为
CPool.GetConnection(long id)

画外音：返回id取模相关联的服务连接。
```

- 只要传入群gid，就能够保证同一个群的请求获取到同一个连接，从而使请求落到同一个服务上。
- 复习：
  - 2019年03月27日

### 《KA，连接池居然这么简单》

- https://mp.weixin.qq.com/s/y8GEAY0R5YXEZZ3erCZJ4A
- 为什么需要连接池
  - 当并发量很低的时候，连接可以临时建立，但当服务吞吐量达到几百、几千的时候，**建立连接connect和销毁连接close就会成为瓶颈**
  - 当服务启动的时候，先建立好若干连接Array[DBClientConnection]
  - 当请求到达的时候，再从Array中取出一个，执行下游操作，执行完放回；
- 连接池核心数据结构是怎样的呢
  - 连接数组Array DBClientConnection[N];
  - `互斥锁`数组Array lock[N];
- 其他考虑
  - 需要实施连接可用性检测，如果有连接失效，需要重建连接；
  - 通过freeArray，connectionMap等数据结构，可以让**取出连接**和**放回连接**都达到O(1)时间复杂度；
  - 可以通过`hash`取连接，实现`id串行化`；
  - 每条连接被取到的概率必须相同，以实现负载均衡；
  - 如果有下游故障，失效连接必须剔除，以实现`故障自动转移`；
  - 如果有下游新增，需要动态扩充连接池，以实现`服务自动发现`；
- 复习：
  - 2019年03月28日

### 《APP还在用域名连接后端？用IP提速N倍》

- https://mp.weixin.qq.com/s/a8LeIvXipokCXddUPm_3FQ
- 移动时代APP的访问特点
  - `网络慢`，DNS解析的时间不能忽略
  - 一旦`DNS被劫持`，整个APP就挂了
- 优化
  - APP第一次访问时，先拉取Web-server的ip-list保存到APP本地；
  - 未来访问时，客户端直接使用ip-list中的IP来访问server，不再需要DNS；
- 跳过了Nginx，如何对Web-server怎么做负载均衡呢
  - APP随机访问ip-list中的IP
- 跳过了Nginx，如何对Web-server做水平扩展呢
  - 直接在`ip-list中增加IP`即可【如何通知客户端更新ip-list】
    - ip-list增加一个版本号，每次拉取ip-list时，同时拿到版本号
    - 如果版本号与本地ip-list版本号一致，则直接使用本地ip-list
    - 版本号变化时，重新拉取ip-list保存到本地
- 复习：
  - 2019年03月27日

### 《为什么别人家的APP，上报日志就这么省流量》

- https://mp.weixin.qq.com/s/J3N4cuh-f93cnt9DcXONcg
- 上报日志的方式：
  - 使用类似于Google Analytics的第三方工具
  - 自己制订私有协议进行上报
    - 节省流量
    - 开发成本高
  - 使用HTTP协议，通过GET参数传递需要上报的数据
    - 可以在Web-Server下放置一个文件，APP发起HTTP请求访问这个文件，通过GET参数传递数据，并通过分析access日志来得到想要的数据。
      - 约定格式法
      - KV法
- 约定格式法：约定分隔符，约定占位符，约定每个字段的含义
  - 扩展性较差，有时候某些字段没有值，也必须在相应的位置保留占位符，因为每个字段的含义都是事先约定好的，要想新增统计项，只能在GET后面新增
- KV法：通过GET参数自解释的KV方式来上报数据
  - 扩展性好
  - 上报数据量比较大，非常消耗流量
- 耗费流量的原因：
  - 无效流量多，HTTP报文有很多无效数据
    - 解决方案：手动构造HTTP请求，尽可能多的去除HTTP中的无效数据
    - *如果使用第三方库构造HTTP请求，可能会带上你并不需要的UA数据。*
    - 自己构造，则可以只保留GET /up HTTP/1.1和GET传递的必须数据；
  - URL冗余，每次都要上报URL
    - 使用尽可能短的域名来接收上报的日志
  - KEY冗余，每次都要上报KEY
    - 使用尽可能短的KEY来标识数据，日志收集方一定要统一规范好KEY
  - 上报频度高，用户每次操作都要日志上报的话，上报量很大
    - 先将数据保存到APP本地存储，再定时上报
- 上报时间：
  - 特殊时间点上报：例如，APP打开，关闭，后台转入活跃时
  - 按时间批量上报：例如，每隔10分钟才上报一次
  - 按数据量批量上报：例如，每收集10条记录才上报一次
- 其他优化方案：
  - 批量上报，数据压缩

### 《互联网公司为啥都不用MySQL分区表》

- https://mp.weixin.qq.com/s/qyc_89wz5Tdgz6FWQfgwLQ
- MySQL 常见的水平切分方案
  - 分库分表
  - 分区表
    - 把一个很大的库（表）的数据分到几个库（表）中，每个库（表）的结构都相同，但他们可以分布在不同的MySQL实例，甚至不同的物理机器上，以达到降低单库（表）数据量，提高读写性能的目的。
- 分区表缺点：
  - 如果SQL不走`分区键`，很容易出现`全表锁`
  - 在分区表实施`关联查询`，就是一个`灾难`
- 当然，在数据量和并发量不太大，或者按照`时间`来存储`冷热数据`或`归档数据`的一些特定场景下，分区表还是有上场机会的
- 复习：
  - 2019年03月28日

### 《离不开的微服务架构，脱不开的RPC细节》

- https://mp.weixin.qq.com/s/CepNdL2A_QMcESgQVZBn2g

- Socket 进程间调用的缺点

  - 入参到字节流的转化，即序列化应用层协议细节
  - socket发送，即网络传输协议细节
  - socket接收
  - 字节流到出参的转化，即反序列化应用层协议细节

- RPC框架的职责

  - 服务调用方client感觉就像调用本地函数一样，来调用服务
  - 服务提供方server感觉就像实现一个本地函数一样，来实现服务
  - **client端**：序列化、反序列化、连接池管理、负载均衡、故障转移、队列管理，超时管理、异步管理等等
  - **server端**：服务端组件、服务端收发包队列、io线程、工作线程、序列化反序列化等

- 序列化：

  - XML

  - JSON

  - 自己实现二进制协议

  - 需要考虑的问题

    - 解析效率：二进制解析快，XML，JSON需要解析DOM树
    - 压缩率：二进制压缩率高，XML，JSON含有冗余数据，压缩率低
    - 扩展性：都挺高
    - 可读性：XML，JSON高
    - 通用性：XML，JSON高

  - 常见的序列化方式：

    - protobuf：Google出品，二进制

  - 发送字节流与接收字节流的方式：

    - 同步调用的代码片段为：

      - *Result = Add(Obj1, Obj2);// 得到Result之前处于阻塞状态*

    - 异步调用的代码片段为：

      ​	Add(Obj1, Obj2, callback);// 调用后直接返回，不等结果

  - 连接池如何实现负载均衡：

    - 连接池在返回连接的时候，需要具备随机性

  - 连接池如何实现故障转移：

    - 当连接池发现某一个机器的连接异常后，需要将这个机器的连接排除掉，返回正常的连接，在机器恢复后，再将连接加回来

  - 如何实现发送超时：

    - 因为是同步阻塞调用，拿到一个连接后，使用带超时的send/recv即可实现带超时的发送和接收。

  - 异步回调有正常回调和超时回调

  - 为什么需要上下文管理器：

    - 由于请求包的发送，响应包的回调都是异步的，甚至不在同一个工作线程中完成，需要一个组件来记录一个请求的上下文，把请求-响应-回调等一些信息匹配起来。

  - 如何将请求-响应-回调这些信息匹配起来 

    - map（请求id，callback）
    - request 和 response都带着请求id

  - 同步RPC-client的核心组件是什么

    - 序列化组件
    - 连接池组件

  - 异步RPC-client的核心组件是什么

    - 序列化组件
    - 连接池组件
    - 收发队列
    - 收发线程
    - 上下文管理器
    - 超时管理器

### 《微服务架构，多“微”才合适》

- https://mp.weixin.qq.com/s/JBGNUvVd9Gcn2yTUZH8-ig
- 服务粒度变细之后，出现一个新的问题，业务与服务的连接关系变复杂了，有什么好的优化方案么
  - 常见的，加入一个高可用服务分发层（Service Mesh不就是这么干的么），并在协议设计时加入服务号，可以减少蜘蛛网状的依赖关系
  - 调用方依赖分发层，传入服务号
  - 分发层依赖服务层，通过服务号参数分发
- 细粒度的优点：
  - 拆得越细，耦合相对会减小
  - 扩容和缩容方便，有利于提高资源利用率
  - 拆得越细，容错相对会更好，一个服务出问题不影响其他服务
  - 扩展性更好
- 细粒度的不足：
  - 拆得越细，系统越复杂
  - 系统之间的依赖关系也更复杂
  - 运维复杂度提升
  - 监控更加复杂
  - 出问题时定位问题更难
- 合适的粒度：
  - 以业务为粒度

### 《群聊比单聊，为什么复杂这么多》

- https://mp.weixin.qq.com/s/M45VySCFFjigXBSHL-LBeA
- 群业务的核心数据结构有两个
  - 群成员表 t_group_users(group_id, user_id, last_ack_msg_id)
  - 群消息表 t_group_msgs(group_id, sender_id, time,msg_id, msg_detail)
- 在线的用户在应用层ACK后，将last_ack_msg_id更新即可
- 批量ACK，是一种常见的，降低请求量的方式
  - 每收到N条群消息ACK一次，这样请求量就降低为原来的1/N了
  - 每隔时间间隔T进行一次群消息ACK，也能达到类似的效果
- 群离线消息过多，拉取过慢，怎么办
  - 分页拉取
  - 按需拉取

### 《拜托，面试别再问我最大值最小值了》

- https://mp.weixin.qq.com/s/hOFzKG9mBUp3TD76mywFYw
- 循环：2n-2次比较
- 分治：1.5n-2

### 《不在线，好友发给我的微信消息，会不会丢》

- https://mp.weixin.qq.com/s/iKRTqY46CD0RGoSkrrYefg
- 消息的可靠性
  - 超时
  - 重传
  - 确认
  - 去重
- 根据业务模式设计表结构
- 根据访问模式设计索引结构
- 按需拉取：
  - 先拉取各个好友的离线消息数量，真正查看离线消息时，才往服务器发送拉取请求
- 可以一次性通过receiver_uid即接收方ID，拉取所有好友发送给用户B的离线消息，把登录时与服务器的交互次数降低为了1次。
- 一次拉取所有的好友的，量太大怎么办？
  - 分页拉取：是一种常见的优化方案。根据业务需求，先拉取最新的一页消息，再按需一页页拉取
    - *包大小与拉取次数的折衷*
- 离线消息返回给用户之后不能直接删除，要等用户ACK之后再删除
- 去重：
  - *SMC理论，系统层面无法做到消息不丢不重，业务层面可以做到对用户无感知*

### 《为什么说，MapReduce，颠覆了互联网分层架构的本质》

- https://mp.weixin.qq.com/s/PhHrDPq1BWIIQBQNFuueew
- service 层连接cache
- 互联网分层架构，是一个CPU固定，数据移动的架构
- mapreduce：
  - 输入数据，被分割为M块后，master会尽量将执行map函数的worker实例，启动在输入数据所在的服务器上。不需要网络传输了
  -  map函数的worker实例输出的的结果，会被分区函数划分成R块，写到worker实例所在的本地磁盘。不需要网络传输了
  - reduce函数，由于有M个输入数据源（M个map的输出都有一部分数据可能对应到一个reduce的输入数据），所以，master会尽量将执行reduce函数的worker实例，启动在离这些输入数据源尽可能“近”的服务器上。最小化网络传输
  - *服务器之间的“近”，可以用内网IP地址的相似度衡量*
- 互联网在线业务的特点：
  - 总数据量大
  - 吞吐量比较大，同时发起的请求多
  - 每个请求，处理的数据相对比较小
  - 用户对处理时延比较敏感
- MapReduce离线业务的优点
  - 吞吐量小，同时发起的任务少
  - 每个任务处理的数据量非常大
  - 用户对处理时延的容忍大
- 这类业务，使用“固定数据，移动CPU”的分层架构是合理的

### 《分布式基础，通俗易懂CAP》

- https://mp.weixin.qq.com/s/tVALLIgO-5ioCp79-i_EIA
- C：数据一致性
- A：系统可用性
- P：节点`连通性`与`扩展性`
- 数据“强一致性”，是希望系统只读到最新写入的数据，例如：通过单点串行化的方式，就能够达到这个效果
- 可用性：运行时间
- 正确的输入，能够取到正确的钱，表示系统可靠
- 取款机7*24小时提供服务，表示系统可用
- 保证高可用的方法：
  - 冗余
  - 故障自动转移
- 互联网，最常见的实践是这样的
- 节点连通性，多节点扩展性，连通性异常的处理必须保证，满足P
- 选择一致性C，举例：传统单库水平切分，就是这类选型的典型
- 选择可用性A，举例：双主库同步高可用，就是这类选型的典型
- 一般不使用强一致性，使用最终一致性
- 最常见的实践是AP+最终一致性

### 《缓存与数据库不一致，咋办》

- https://mp.weixin.qq.com/s/gYQvP69sao8U0azuNRMG1w
- 数据库主从不一致
  - 主动同步完成之前，会读取到旧数据
  - 主从不一致的影响时间很短
- 缓存与数据库不一致
  - 主从同步没有完成，缓存中放入了旧数据
  - 加入缓存后，导致的不一致影响时间会很长
- 解决方法：
  - 主从同步
  - 通过工具订阅从库的binlog，这里能够最准确的知道，从库数据同步完成的时间
  - 从库执行完写操作，**向缓存再次发起删除**，淘汰这段时间内可能写入缓存的旧数据
  - *也只有一个很小的时间间隔，可能读到旧数据*

### 《究竟先操作缓存，还是数据库》

- 缓存的核心是读加速原理

