## 公众号《架构师之路》阅读笔记

### 《究竟啥才是互联网架构“高可用”》

- https://mp.weixin.qq.com/s/p0LsxT-JUS7zYg23M7nupQ

- 高可用主要指 “`时间`”
- `单点`是高可用的大敌
- 保证高可用的核心是：`冗余（集群）`
- 避免人工恢复故障：`自动故障转移`
- 架构的每一层都要做 冗余 + 自动故障转移
  - 反向代理层：以nginx为例：有两台nginx，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是`keepalived`存活探测，相同`virtual IP`提供服务。当nginx挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到`shadow-nginx`，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的。
  - 站点层：假设反向代理层是`nginx`，`nginx.conf`里能够配置多个web后端，并且nginx能够探测到多个后端的存活性。当web-server挂了的时候，nginx能够探测到，会自动的进行故障转移，将流量自动迁移到其他的web-server，整个过程由`nginx自动完成`，对调用方是透明的。
  - 服务层：`“服务连接池”`会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。当service挂了的时候，service-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的service，整个过程由连接池自动完成，对调用方是透明的（所以说RPC-client中的服务连接池是很重要的基础组件）。
  - 缓存层：
    - 利用客户端的封装，service对cache进行双读或者双写。缓存层也可以通过支持主从同步的缓存集群来解决缓存层的高可用问题。以redis为例，redis天然支持主从同步，redis官方也有sentinel哨兵机制，来做redis的存活性检测。当redis主挂了的时候，sentinel能够探测到，会通知调用方访问新的redis，整个过程由`sentinel和redis集群`配合完成，对调用方是透明的。
    - 将kv缓存封装成服务集群，上游设置一个代理（代理可以用集群冗余的方式保证高可用），代理的后端根据缓存访问的key水平切分成若干个实例，每个实例的访问并不做高可用。缓存实例挂了屏蔽：当有水平切分的实例挂掉时，代理层直接返回cache miss，此时缓存挂掉对调用方也是透明的。key水平切分实例减少，不建议做re-hash，这样容易引发缓存数据的不一致。
  - 数据库层：大部分互联网技术，数据库层都用了“`主从同步，读写分离`”架构，所以数据库层的高可用，又分为“读库高可用”与“写库高可用”两类。`写master，读slave`
    - 读的高可用：既然冗余了读库，一般来说就至少有2个从库，“`数据库连接池`”会建立与读库多个连接，每次请求会路由到这些读库。当读库挂了的时候，db-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的读库，整个过程由连接池自动完成，对调用方是透明的（所以说DAO中的数据库连接池是很重要的基础组件）。
    - 写的高可用：以mysql为例，可以设置两个`mysql双主同步`，一台对线上提供服务，另一台冗余以保证高可用，常见的实践是`keepalived存活探测`，相同virtual IP提供服务。自动故障转移：当写库挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-db-master，由于使用的是相同的virtual IP，这个切换过程对调用方是透明的

### 《怎么理解分布式、高并发、多线程？》

- https://mp.weixin.qq.com/s/k1Fz0NCN8KyV3VHF0nSGuA
- 分布式
  - 水平扩展：当一台机器扛不住流量时，就通过添加机器的方式，将流量平分到所有服务器上，所有机器都可以提供相当的服务
  - 垂直扩展：前端有多种查询需求时，一台机器扛不住，可以将不同的需求分发到不同的机器上，比如A机器处理余票查询的请求，B机器处理支付的请求。
- 高并发：
  - 高并发可以通过`分布式`技术去解决，将并发流量分到不同的物理服务器上。但除此之外，还可以有很多其他优化手段：比如使用`缓存系统`，将所有的，`静态内容放到CDN等`；还可以使用`多线程`技术将一台服务器的服务能力最大化。
    - 服务并发低时候写数据库，并发高时候通过消息队列写缓存。缓存定期持久化到数据库
    - 服务读数据直接从缓存读

### 《一次彻底搞透协议设计》

- https://mp.weixin.qq.com/s/wr7chJqpOBbv3M3JXD1wXg
- 分层：
  - 应用层
    - 文本（HTTP）
      - 可读性好，可扩展性好，解析效率不高，对二进制不友好
    - 二进制（IP）
      - 定长包头，可扩展变长包体，每个字段有固定的含义
      - 可读性差，难以调试。扩展性不好。解析效率高。支持二进制流
      - Protobuf 是常见的变长包体协议
    - 流式XML（XMPP）
      - 可读性好，扩展性好
      - 解析代价超高，DOM树
      - 有效数据传输效率低
      - 对二进制不友好
  - 安全层
    - SSL
    - 自己实现
      - 一人一密（uid，手机号，qq号等）
      - 一次一密
  - 传输层
    - TCP
    - epoll 可以抗单机几十万连接

### 《互联网架构，究竟为啥要做服务化》

- https://mp.weixin.qq.com/s/S6ga8y88qaAjbKjuKMrowQ
- 没有服务层的痛点：
  - 代码到处拷贝：在有用户服务之前，各个业务线都是自己通过DAO写SQL访问user库来存取用户数据，这无形中就导致了代码的拷贝。
  - 复杂性扩散：如果没有统一的服务层，各个业务线都需要关注`缓存的引入`导致的复杂性。如果没有统一的服务层，各个业务线都需要关注`分库分表的引入`导致的复杂性。
  - 库的复用与耦合：库的版本维护会导致业务线之间的耦合。
  - SQL质量无法保障，业务互相影响：假如业务线A写了一个全表扫描的SQL，导致数据库的CPU100%，影响的不只是一个业务线，而是所有的业务线都会受影响。
  - DB耦合：典型的，通过join数据表来实现各自业务线的一些业务逻辑。
- 引入服务层的好处：
  - 调用方便
  - 复用性高，避免代码拷贝：所有user数据的存取，都通过user-service来进行，代码只此一份，不存在拷贝。升级一处升级，bug修改一处修改。
  - 屏蔽底层复杂度：在没有服务层之前，所有业务线都需要关注缓存、分库分表这些细节。
  - SQL质量得到保障
  - 数据库解耦
  - 服务层提供有限接口，无限性能：服务化之后，服务只提供有限的通用接口，理论上服务集群能够提供无限性能，性能出现瓶颈，服务层一处集中优化。

### 《拜托，面试别再问我TopK了》

- https://mp.weixin.qq.com/s/FFsvWXiaZK96PtUg-mmtEw
- 排序：O(n*lg(n))
- 局部排序（冒泡）：O(n*k)
- 堆：O(n*lg(k))
  - 每一次堆调整是lg(k)
- 随机选择：
  - 分治法：子问题都要解决（快排）
  - 减治法：子问题只解决一个（二分查找）
  - 转化为使用`快排的partition求第k大的数O(n)`

- 复习时间：
  - 2019年03月25日





### 《数据库索引，到底是什么做的》

- https://mp.weixin.qq.com/s/YMbRJwyjutGMD1KpI_fS0A
- 数据库建立索引是为了提高`查找`速度
- 索引为什么不设计成哈希，而是设计成为树形
  - 索引设计成树形，和SQL的需求相关。
  - 但是对于**排序查询**的SQL需求：**哈希**型的索引，时间复杂度会退化为O(n)，而**树型**的“有序”特性，依然能够保持O(log(n)) 的高效率。
  - InnoDB并`不支持`哈希索引。
- 二叉树为什么不用来做索引
  - 当数据量大的时候，树的`高度会比较高`，数据量大的时候，查询会比较慢；
  - 每个节点只存储一个记录，可能导致一次查询有很多次磁盘IO；
- B树：
  - 不再是二叉搜索，而是m叉搜索；高度能够大大降低；
  - 叶子节点，非叶子节点，都存储数据；
  - B树被作为实现索引的数据结构被创造出来，是因为它能够完美的利用“局部性原理”。每个节点可以存储j个记录，如果将节点大小设置为页大小，例如4K，能够充分的利用预读的特性，极大减少磁盘IO；
  - 获取所有的节点需要`中序遍历`
- B+树
  - 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上；
  - 叶子之间，增加了链表，获取所有节点，`不再需要中序遍历`；
  - 范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯；
  - 叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储；
  - 非叶子节点，不存储实际记录，而只存储记录的KEY的话，`那么在相同内存的情况下，B+树能够存储更多索引`；

- 复习时间：
  - 2019年03月25日



### 《1分钟了解MyISAM与InnoDB的索引差异》

- https://mp.weixin.qq.com/s/FUXPXKfKyjxAvMUFHZm9UQ

- MyISAM的索引
  - MyISAM的索引与行记录是分开存储的，叫做**非聚集索引**（UnClustered Index）
  - 有连续聚集的区域单独存储行记录
  - 主键索引的叶子节点，存储主键，与对应行记录的指针
  - 普通索引的叶子结点，存储索引列，与对应行记录的指针
- InnoDB的索引
  - InnoDB的**主键索引与**行记录是存储在一起的，故叫做**聚集索引**（Clustered Index）：
  - 没有单独区域存储行记录
  - 键索引的叶子节点，存储主键，与对应行记录（而不是指针）
  - 普通索引的叶子节点，存储主键（也不是指针）
  - 不建议使用较长的列做主键，例如char(64)，因为所有的普通索引都会存储主键，会导致普通索引过于庞大；
  - 建议使用趋势递增的key做主键，由于数据行与索引一体，这样不至于插入记录时，有大量索引分裂，行记录移动；
  - 查询普通索引其实扫了两遍索引树，先查普通索引找到主键，然后通过主键索引找到行记录

### 《InnoDB并发如此高，原因竟然在这》

- 技术上如何进行并发控制
  - 锁
  - 数据多版本
- 数据多版本（写时也能读）
  - 写任务发生时，将数据克隆一份，以版本号区分；
  - 写任务操作新克隆的数据，直至提交；
  - 并发读任务可以继续读取旧版本的数据，不至于阻塞
- redo
  - 磁盘**随机写**性能较低，如果每次都刷盘，会极大影响数据库的吞吐量。
  - 将修改行为先写到redo日志里（此时变成了**顺序写**），再定期将数据刷到磁盘上，这样能极大提高性能。
- MVVC 读取的旧版本数据在哪
  - 旧版本数据存储在回滚段里；
- InnoDB为何能够做到这么高的并发
  - 回滚段里的数据，其实是历史数据的快照（snapshot），这些数据是不会被修改，select可以肆无忌惮的并发读取他们。
  - **快照读**（Snapshot Read），这种**一致性不加锁的读**（Consistent Nonlocking Read），就是InnoDB并发如此之高的核心原因之一。
- 什么样的select是快照读？
  - 除非显示加锁，普通的select语句都是快照读
  - 这里的显示加锁，非快照读是指：
    - select … lock in share mode
    - select … for update

### 《InnoDB，5项最佳实践，知其所以然》

- https://mp.weixin.qq.com/s/JEJcgD36dpKgbUi7xo6DzA
- 关于count(*)
  - MyISAM会直接存储总行数，InnoDB则不会，需要按行扫描
  - 数据量大的表，InnoDB不要轻易select count(*)，性能消耗极大
  - 只有查询全表的总行数，MyISAM才会直接返回结果，当加了where条件后，两种存储引擎的处理方式类似
- 关于全文索引
  - MyISAM支持全文索引，InnoDB5.6之前不支持全文索引
  - 不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用数据库自带的全文索引，会导致小量请求占用大量数据库资源
  - 大数据量+高并发量的业务场景，全文索引，MyISAM也不是最优之选
- 关于事务
  - MyISAM不支持事务，InnoDB支持事务
  - 事务是选择InnoDB非常诱人的原因之一，它提供了commit，rollback，崩溃修复等能力。在系统异常崩溃时，MyISAM有一定几率造成文件损坏，这是非常烦的。但是，事务也非常耗性能，会影响吞吐量，建议只对一致性要求较高的业务使用复杂事务
  - MyISAM可以通过lock table表锁，来实现类似于事务的东西，但对数据库性能影响较大，强烈不推荐使用
- 关于外键
  - MyISAM不支持外键，InnoDB支持外键
  - 不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用外键，而建议由应用程序保证完整性
- 关于行锁与表锁
  - MyISAM只支持表锁，InnoDB可以支持行锁
  - 只要数据量和并发量较大，一律使用InnoDB
  - InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁
- InnoDB两个最牛逼的特点
  - 行锁
  - 事务

### 《InnoDB行锁，如何锁住一条不存在的记录》

- https://mp.weixin.qq.com/s/JLdprFfpZoK_v4zkw-EVbg
- MySQL默认的事务隔离级别是 Repeated Read (RR)
  - 读取到数据，都是其他事务已提交的数据
  - 同一个事务中，相同的连续读，得到的结果应该是相同的
  - 不会出现insert幻象读

### 《InnoDB，快照读，在RR和RC下有何差异》

- https://mp.weixin.qq.com/s/gjt9WdyTQRzx-hr_qIz_mw
- 读已提交：
  - 它解决“读脏”问题，保证读取到的数据行都是已提交事务写入的
  - 它可能存在“读幻影行”问题，同一个事务里，连续相同的read可能读到不同的结果集
- 可重复读
  - 它不但解决“读脏”问题，还解决了“读幻影行”问题，同一个事务里，连续相同的read读到相同的结果集
- 结论：
  - RC下，快照读总是能读到最新的行数据快照，当然，必须是已提交事务写入的
  - RR下，某个事务首次read记录的时间为T，未来不会读取到T时间之后已提交事务写入的记录，以保证连续相同的read读到相同的结果集（和事务开始时间无关，和首次读时间有关）
- 总结：
  - RR下，事务在第一个Read操作时，会建立Read View
  - RC下，事务在每次Read操作时，都会建立Read View

### 《插入InnoDB自增列，居然是表锁》

- https://mp.weixin.qq.com/s/kOMSD_Satu9v9ciZVvNw8Q
- 自增锁是一种特殊的**表级别锁**（table-level lock）
- 如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。

### 《InnoDB并发插入，居然使用意向锁》

- https://mp.weixin.qq.com/s/iViStnwUyypwTkQHWDIR_w
- 意向锁的特点：
  - 意向锁，是一个表级别的锁(table-level locking)
  - **意向共享锁**(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁
    - select ... lock in share mode，要设置**IS锁**
  - **意向排它锁**(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁
    - select ... for update，要设置**IX锁**
- 意向锁协议：
  - 事务要获得某些行的S锁，必须先获得表的IS锁
  - 意向锁是兼容的，不是互斥的
- 插入意向锁：
  - 多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。
- InnoDB使用**插入意向锁**，可以提高插入并发；

### 《消息顺序性为何这么难》

- https://mp.weixin.qq.com/s/wF-jqn9QZAC8qsof3aAPoQ
- 邮件展示顺序，其实是以客户端发送时间为准的
- 秒杀活动时间判断，肯定得以服务器的时间为准，不可能让客户端修改本地时间，就能够提前秒杀
- 对于严格时序的业务场景，可以利用单点写db的seq/auto_inc_id生成单调递增的id，来保证顺序性。
  - 单点容易成为瓶颈
- 如果能接受误差不大
  - 可以始终分布式id生成算法来生成id，作为时序依据。
- 单点序列化
  - 数据库主从同步
  - GFS中文件的一致性
    - GFS(Google File System)为了保证文件的可用性，一份文件要存储多份，在多个上游对同一个文件进行写操作时，也是由一个主chunk-server先序列化写操作，再将序列化后的操作发送给其他chunk-server，来保证冗余文件的数据一致性的。
  - 单发消息：
    - 客户端序列化
  - 群发消息，服务器收到消息之后做服务器端单点序列化
    - 缺点：生成全局递增序列号的服务很容易成为系统瓶颈。
    - 改进：service做单点序列生成。保证一个群的消息落在同一个service上，这个service就可以用本地seq来序列化同一个群的所有消息，保证所有群友看到消息的时序是相同的。【id串行化】

### 《“ID串行化”是如何保证消息顺序性的》

- https://mp.weixin.qq.com/s/LgaiSqJGqX5a9JB1WSZ2_w
- 让同一个群gid的所有消息落在同一台服务器上处理

```
对连接池进行少量改动，获取连接时：
CPool.GetConnection()

画外音：返回任何一个可用服务连接。

升级为
CPool.GetConnection(long id)

画外音：返回id取模相关联的服务连接。
```

- 只要传入群gid，就能够保证同一个群的请求获取到同一个连接，从而使请求落到同一个服务上。